{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534f3bfe",
   "metadata": {},
   "source": [
    "# <center> Необходимо предсказать биологический ответ молекул (столбец 'Activity') по их химическому составу (столбцы D1-D1776)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa92dea8",
   "metadata": {},
   "source": [
    "###### Примечание. \n",
    "###### Ориентировочное время отработки ноутбука составляет 30 минут"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18555338",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7031f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "\n",
    "from sklearn import linear_model #линейные моделиё\n",
    "from sklearn import tree #деревья решений\n",
    "from sklearn import ensemble #ансамбли\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import preprocessing #предобработка\n",
    "from sklearn.model_selection import train_test_split #сплитование выборки\n",
    "from sklearn import model_selection #методы разделения и валидации\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# методы подбора гиперпараметров\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "import optuna\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "random_state = 42\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19679fe1",
   "metadata": {},
   "source": [
    "### Прочитаем данные и посмотрим на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5bbc0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('_train_sem09 (1).csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438d24f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3751 entries, 0 to 3750\n",
      "Columns: 1777 entries, Activity to D1776\n",
      "dtypes: float64(942), int64(835)\n",
      "memory usage: 50.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87b95f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2034\n",
      "0    1717\n",
      "Name: Activity, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.Activity.value_counts())\n",
    "sns.countplot(data=df, x='Activity');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d097d84",
   "metadata": {},
   "source": [
    "Классы целевой переменной сбалансированы, поэтому при разбиении stratify можем не использовать (при попытке использовать значение f1_score уменьшается)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833995ca",
   "metadata": {},
   "source": [
    "### <center> Т.к. данные подготовлены (из условий задачи), можно сразу построить первую модель на всех признаках без подбора параметров, чтобы получить базовое значение метрики f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a4f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделим из датафрейма матрицу наблюдений X и вектор целевого признака y\n",
    "X = df.drop('Activity', axis = 1)\n",
    "y = df['Activity']\n",
    "\n",
    "# Разобъем данные на тренировочную, валидационную и тестовые выборки.\n",
    "# Обучаем не тренировочной, подбираем параметры на валидационной, тестируем на тестовой.\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, \n",
    "                                                      y,\n",
    "                                                      #stratify = y,\n",
    "                                                      test_size = 0.2,\n",
    "                                                      random_state = random_state\n",
    "                                                     )\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, \n",
    "                                                    y_valid,\n",
    "                                                    #stratify = y_valid,\n",
    "                                                    test_size = 0.5, \n",
    "                                                    random_state = random_state\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "446f1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализуем данные\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca200c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Logistic Regression\n",
      "Базовое значение f1_score для нормализованной тренировочной выборки составляет: 0.889\n",
      "Базовое значение f1_score для нормализованной валидационной выборки составляет: 0.775\n",
      "Базовое значение f1_score для нормализованной тестовой выборки составляет: 0.802\n"
     ]
    }
   ],
   "source": [
    "# Обучим базовую модель Линейной Регрессии и получим предсказания и f1_score для валидационной и тестовой выборок\n",
    "\n",
    "lr = linear_model.LogisticRegression(random_state = random_state)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_tr_lr = lr.predict(X_train_scaled)\n",
    "y_pred_val_lr = lr.predict(X_valid_scaled)\n",
    "y_pred_test_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "f1_score_tr = round(metrics.f1_score(y_train, y_pred_tr_lr),3)\n",
    "f1_score_val = round(metrics.f1_score(y_valid, y_pred_val_lr),3)\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_lr),3)\n",
    "\n",
    "print('Модель Logistic Regression')\n",
    "print(f'Базовое значение f1_score для нормализованной тренировочной выборки составляет: {f1_score_tr}')\n",
    "print(f'Базовое значение f1_score для нормализованной валидационной выборки составляет: {f1_score_val}')\n",
    "print(f'Базовое значение f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ed71732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Random Forest\n",
      "Базовое значение f1_score для нормализованной тренировочной выборки составляет: 1.0\n",
      "Базовое значение f1_score для нормализованной валидационной выборки составляет: 0.828\n",
      "Базовое значение f1_score для нормализованной тестовой выборки составляет: 0.828\n"
     ]
    }
   ],
   "source": [
    "# Обучим базовую модель Случайный Лес и получим предсказания и f1_score для валидационной и тестовой выборок\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier(random_state = random_state)\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_tr_rfc = rfc.predict(X_train_scaled)\n",
    "y_pred_val_rfc = rfc.predict(X_valid_scaled)\n",
    "y_pred_test_rfc = rfc.predict(X_test_scaled)\n",
    "\n",
    "f1_score_tr = round(metrics.f1_score(y_train, y_pred_tr_rfc),3)\n",
    "f1_score_val = round(metrics.f1_score(y_valid, y_pred_val_rfc),3)\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_rfc),3)\n",
    "\n",
    "print('Модель Random Forest')\n",
    "print(f'Базовое значение f1_score для нормализованной тренировочной выборки составляет: {f1_score_tr}')\n",
    "print(f'Базовое значение f1_score для нормализованной валидационной выборки составляет: {f1_score_val}')\n",
    "print(f'Базовое значение f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed9db5",
   "metadata": {},
   "source": [
    "Значение f1_score, которое мы получили с помощью базового алгоритма Random Forest лучше, чем у базового алгоритма Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b872c45",
   "metadata": {},
   "source": [
    "Посчитаем значение f1_score на кросс-валидации StratifiedKFold для 5 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af30409b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.805426</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.794953</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802379</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>0.798151</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.814219</td>\n",
       "      <td>0.015611</td>\n",
       "      <td>0.807512</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785961</td>\n",
       "      <td>0.015618</td>\n",
       "      <td>0.812698</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.806181</td>\n",
       "      <td>0.015611</td>\n",
       "      <td>0.819723</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.805426    0.015702    0.794953          1.0\n",
       "1  0.802379    0.015627    0.798151          1.0\n",
       "2  0.814219    0.015611    0.807512          1.0\n",
       "3  0.785961    0.015618    0.812698          1.0\n",
       "4  0.806181    0.015611    0.819723          1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочное значение f1_score на кросс-валидации составило:  1.0\n",
      "Тестовое значение f1_score на кросс-валидации составило:  0.807\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект кросс-валидатора StratifiedKFold\n",
    "skf = model_selection.StratifiedKFold(n_splits = 5)\n",
    "\n",
    "#Считаем метрики на кросс-валидации StratifiedKFold\n",
    "cv_metrics = model_selection.cross_validate(estimator = rfc, #модель \n",
    "                                            X = X_train_scaled, #матрица наблюдений X\n",
    "                                            y = y_train, #вектор ответов y\n",
    "                                            cv = skf, #кросс-валидатор\n",
    "                                            scoring = 'f1', #метрика\n",
    "                                            return_train_score = True #подсчёт метрики на тренировочных фолдах\n",
    "                                           )\n",
    "display(pd.DataFrame(cv_metrics))\n",
    "print('Тренировочное значение f1_score на кросс-валидации составило: ', round(cv_metrics['train_score'].mean(),3))\n",
    "print('Тестовое значение f1_score на кросс-валидации составило: ', round(cv_metrics['test_score'].mean(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e62ad8",
   "metadata": {},
   "source": [
    "На кросс-валидации значение метрики f1_score хуже, чем на Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e867ec",
   "metadata": {},
   "source": [
    "## <center> Проведем 2 вида оптимизации: базовую и прдвинутую для 2-х вариантов моделей: Логистическая Регрессия и Случайный Лес"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1477a77",
   "metadata": {},
   "source": [
    "### <center> Базовая оптимизация включает в себя алгоритмы: GridSearchCV и RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482ea04",
   "metadata": {},
   "source": [
    " ### <center> 1. GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39078542",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры для Логистической Регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7cc1718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 10s\n",
      "accuracy на валидационном наборе: 0.74\n",
      "f1_score на валидационном наборе: 0.77\n",
      "Наилучшие значения гиперпараметров: {'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty': ['l2', 'none'], # тип регурялизации\n",
    "              'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'] # алгоритм оптимизации\n",
    "              }\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, # генератор случайных чисел\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "\n",
    "%time grid_search.fit(X_train_scaled, y_train) \n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(grid_search.score(X_valid_scaled, y_valid)))\n",
    "y_valid_pred = grid_search.predict(X_valid_scaled)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e814794",
   "metadata": {},
   "source": [
    "В результате значение f1_score для валидационной выборки не увеличился по сравнению с базовым значением\n",
    "\n",
    "Попробуем расширить сетку гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0057316f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 48s\n",
      "accuracy на валидационном наборе: 0.74\n",
      "f1_score на валидационном наборе: 0.77\n",
      "Наилучшие значения гиперпараметров: {'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty': ['l2', 'none'], # тип регурялизации\n",
    "              'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'], # алгоритм оптимизации\n",
    "              'max_iter': [100, 1500, 500] # количество итераций на сходимость\n",
    "              }\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, # генератор случайных чисел\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "\n",
    "%time grid_search.fit(X_train_scaled, y_train) \n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(grid_search.score(X_valid_scaled, y_valid)))\n",
    "y_test_pred = grid_search.predict(X_valid_scaled)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_pred_val_lr)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57e92f0",
   "metadata": {},
   "source": [
    "Снова изменений нет, хотя времени понадобилось в 4 раза больше.\n",
    "\n",
    "Попробуем еще один раз - добавим коэффициент регуляризации, но уменьшим количество алгоритмов сходимости и вариации max_iter, потому что нужно будет очень много времени для расчетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f5beeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 5s\n",
      "accuracy на валидационном наборе: 0.74\n",
      "f1_score на валидационном наборе: 0.77\n",
      "Наилучшие значения гиперпараметров: {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty': ['l2', 'none'], # тип регурялизации\n",
    "              'solver': ['lbfgs', 'newton-cg'], # алгоритм оптимизации\n",
    "              'max_iter': [100, 1000], # количество итераций на сходимость\n",
    "              'C': [0.01, 1] # уровень силы регурялизации\n",
    "              }\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, # генератор случайных чисел\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "\n",
    "%time grid_search.fit(X_train_scaled, y_train) \n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(grid_search.score(X_valid_scaled, y_valid)))\n",
    "y_test_pred = grid_search.predict(X_valid_scaled)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_pred_val_lr)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d35665d",
   "metadata": {},
   "source": [
    "Результат тот же\n",
    "\n",
    "Посчитаем значение f1_score на тестовой выборке с подобранными гиперпараметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d4779db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая модель:\n",
      "LogisticRegression(C=1, random_state=42, solver='newton-cg')\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшая модель:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c43167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Logistic Regression с подобранными гиперпараметрами GridSearchCV\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.806\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(C = 1, random_state = random_state, solver = 'newton-cg')\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_test_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_lr),3)\n",
    "\n",
    "print('Модель Logistic Regression с подобранными гиперпараметрами GridSearchCV')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacd9aa",
   "metadata": {},
   "source": [
    "Результат для тестовой выборки улучшен.\n",
    "\n",
    "Для базовой модели: f1_score = 0.802\n",
    "\n",
    "Для GridSearchCV модели: f1_score = 0.806"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb764e",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры для Случайного Леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2e50960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.68 s\n",
      "f1_score на обучающем наборе: 0.94\n",
      "accuracy на валидационном наборе: 0.82\n",
      "f1_score на валидационном наборе: 0.84\n",
      "Наилучшие значения гиперпараметров: {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': list(range(80, 100, 150)),\n",
    "              'min_samples_leaf': [5, 7],\n",
    "              'max_depth': list(np.linspace(20, 40, 5, dtype = int))\n",
    "              }\n",
    "            \n",
    "grid_search_forest = GridSearchCV(\n",
    "    estimator = ensemble.RandomForestClassifier(random_state = random_state), \n",
    "    param_grid = param_grid, \n",
    "    cv = 5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_forest.fit(X_train_scaled, y_train) \n",
    "y_train_pred = grid_search_forest.predict(X_train_scaled)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(grid_search_forest.score(X_valid_scaled, y_valid)))\n",
    "y_valid_pred = grid_search_forest.predict(X_valid_scaled)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48359923",
   "metadata": {},
   "source": [
    "Смогли улучшить значение f1_score (и accuracy тоже), попробуем еще расширить сетку параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "508905e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.9 s\n",
      "f1_score на обучающем наборе: 0.95\n",
      "accuracy на валидационном наборе: 0.80\n",
      "f1_score на валидационном наборе: 0.82\n",
      "Наилучшие значения гиперпараметров: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 5, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': list(range(80, 100, 150)),\n",
    "              'min_samples_leaf': [5, 7],\n",
    "              'max_depth': list(np.linspace(20, 40, 5, dtype = int)),\n",
    "              'criterion': ['gini', 'entropy']\n",
    "              }\n",
    "            \n",
    "grid_search_forest = GridSearchCV(\n",
    "    estimator = ensemble.RandomForestClassifier(random_state = random_state), \n",
    "    param_grid = param_grid, \n",
    "    cv = 5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_forest.fit(X_train_scaled, y_train) \n",
    "y_train_pred = grid_search_forest.predict(X_train_scaled)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(grid_search_forest.score(X_valid_scaled, y_valid)))\n",
    "y_valid_pred = grid_search_forest.predict(X_valid_scaled)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a00243a",
   "metadata": {},
   "source": [
    "Значение целевой метрики ухудшилось, откатимся к предыдущему варианту и посчитаем f1_score на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "367c58f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Random Forest с подобранными гиперпараметрами GridSearchCV\n",
      "f1_score для нормализованной валидационной выборки составляет: 0.837\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.831\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(max_depth = 30, \n",
    "                                      min_samples_leaf = 5, \n",
    "                                      n_estimators = 80, \n",
    "                                      random_state = random_state)\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_val_rfc = rfc.predict(X_valid_scaled)\n",
    "y_pred_test_rfc = rfc.predict(X_test_scaled)\n",
    "\n",
    "f1_score_val = round(metrics.f1_score(y_valid, y_pred_val_rfc),3)\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_rfc),3)\n",
    "\n",
    "print('Модель Random Forest с подобранными гиперпараметрами GridSearchCV')\n",
    "print(f'f1_score для нормализованной валидационной выборки составляет: {f1_score_val}')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b77014",
   "metadata": {},
   "source": [
    "Результат для тестовой выборки улучшен.\n",
    "\n",
    "Для базовой модели: f1_score = 0.828\n",
    "\n",
    "Для GridSearchCV модели: f1_score = 0.831"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889cc128",
   "metadata": {},
   "source": [
    "Не знаю, почему, но параметр max_depth = 30 дает лучший результат, чем max_depth = 20.. \n",
    "\n",
    "Хотя предыдущий вариант лучших параметров говорит нам о том, что нужно использовать max_depth = 20\n",
    "\n",
    "Попробуем провести кросс-валидацию на 5 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "911f8826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734763</td>\n",
       "      <td>0.015618</td>\n",
       "      <td>0.786624</td>\n",
       "      <td>0.943323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750949</td>\n",
       "      <td>0.015599</td>\n",
       "      <td>0.806107</td>\n",
       "      <td>0.943951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579041</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.940948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.641086</td>\n",
       "      <td>0.015630</td>\n",
       "      <td>0.802488</td>\n",
       "      <td>0.945935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.703129</td>\n",
       "      <td>0.015615</td>\n",
       "      <td>0.819970</td>\n",
       "      <td>0.939218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.734763    0.015618    0.786624     0.943323\n",
       "1  0.750949    0.015599    0.806107     0.943951\n",
       "2  0.579041    0.015625    0.790123     0.940948\n",
       "3  0.641086    0.015630    0.802488     0.945935\n",
       "4  0.703129    0.015615    0.819970     0.939218"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочное значение f1_score на кросс-валидации составило:  0.943\n",
      "Тестовое значение f1_score на кросс-валидации составило:  0.801\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект кросс-валидатора StratifiedKFold\n",
    "skf = model_selection.StratifiedKFold(n_splits = 5)\n",
    "\n",
    "#Считаем метрики на кросс-валидации StratifiedKFold\n",
    "cv_metrics = model_selection.cross_validate(estimator = rfc, #модель \n",
    "                                            X = X_train_scaled, #матрица наблюдений X\n",
    "                                            y = y_train, #вектор ответов y\n",
    "                                            cv = skf, #кросс-валидатор\n",
    "                                            scoring = 'f1', #метрика\n",
    "                                            return_train_score = True #подсчёт метрики на тренировочных фолдах\n",
    "                                           )\n",
    "display(pd.DataFrame(cv_metrics))\n",
    "print('Тренировочное значение f1_score на кросс-валидации составило: ', round(cv_metrics['train_score'].mean(),3))\n",
    "print('Тестовое значение f1_score на кросс-валидации составило: ', round(cv_metrics['test_score'].mean(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea44c65",
   "metadata": {},
   "source": [
    "Кросс-валидация дает хуже результат, чем обычная тест выборка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2258c7",
   "metadata": {},
   "source": [
    "#### Выводы по GridSearchCV\n",
    "\n",
    "1. GridSearchCV для Логистической регрессии немного увеличил значение целевой метрики осталось неизменным. Долго происходит подбор параметров.\n",
    "\n",
    "2. GridSearchCV для Случайного Леса принес результат - подобрав параметры мы смогли увеличить значение целевой метрики. Параметры считаются (подбираются) быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e6f5d3",
   "metadata": {},
   "source": [
    " ### <center> 2. RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29102b99",
   "metadata": {},
   "source": [
    "Подберем параметры для Логистичекой регрессии, обучим модель с этими параметрами и сравним результат с базовым значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fe9661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 55s\n",
      "accuracy на валидационном наборе: 0.74\n",
      "f1_score на валидационном наборе: 0.77\n",
      "Наилучшие значения гиперпараметров: {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 100, 'C': 0.34}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {'penalty': ['l2', 'none'],\n",
    "                       'solver': ['lbfgs', 'newton-cg'],\n",
    "                       'C': list(np.linspace(0.01, 1, 10, dtype=float)),\n",
    "                       'max_iter': [100, 1000]\n",
    "                       },\n",
    "            \n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    cv=5, \n",
    "    n_iter = 10, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search.fit(X_train_scaled, y_train) \n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(random_search.score(X_valid_scaled, y_valid)))\n",
    "y_valid_pred = random_search.predict(X_valid_scaled)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f85f77c",
   "metadata": {},
   "source": [
    "Удалось увеличить значение f1_score на валидационной выборке\n",
    "\n",
    "Попробуем построить на этих параметрах модель и получить значение целевой метрики на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61cc029a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Logistic Regression с подобранными гиперпараметрами GridSearchCV\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.799\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(C = 0.12, \n",
    "                                     max_iter = 1000, \n",
    "                                     penalty = 'l2', \n",
    "                                     solver='newton-cg', \n",
    "                                     random_state = random_state)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_test_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_lr),3)\n",
    "\n",
    "print('Модель Logistic Regression с подобранными гиперпараметрами GridSearchCV')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff71ee2e",
   "metadata": {},
   "source": [
    "Результат для тестовой выборки не улучшен.\n",
    "\n",
    "Для базовой модели: f1_score = 0.802\n",
    "\n",
    "Для GridSearchCV модели: f1_score = 0.806\n",
    "\n",
    "Для RandomizedSearchCV модели: f1_score = 0.799"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7760865b",
   "metadata": {},
   "source": [
    "Подберем параметры для случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "666c0a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 s\n",
      "f1_score на обучающем наборе: 0.94\n",
      "accuracy на валидационном наборе: 0.82\n",
      "f1_score на валидационном наборе: 0.83\n",
      "Наилучшие значения гиперпараметров: {'n_estimators': 140, 'min_samples_leaf': 5, 'max_depth': 35, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {'n_estimators': list(range(80, 200, 30)),\n",
    "                       'min_samples_leaf': [5, 7, 12],\n",
    "                       'max_depth': list(np.linspace(20, 40, 10, dtype = int)),\n",
    "                       'criterion': ['gini', 'entropy', 'log_loss']\n",
    "                      }\n",
    "            \n",
    "random_search_forest = RandomizedSearchCV(\n",
    "    estimator = ensemble.RandomForestClassifier(random_state = random_state), \n",
    "    param_distributions = param_distributions, \n",
    "    cv = 5,\n",
    "    n_iter = 10, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search_forest.fit(X_train_scaled, y_train) \n",
    "y_train_pred = random_search_forest.predict(X_train_scaled)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(random_search_forest.score(X_valid_scaled, y_valid)))\n",
    "y_valid_pred = random_search_forest.predict(X_valid_scaled)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae22afae",
   "metadata": {},
   "source": [
    "Значение целевой метрики на валидационных данных улучшилось, попробуем подставить параметры в модель и проверить значение f1_score на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83d55858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Random Forest с подобранными гиперпараметрами RandomizedSearchCV\n",
      "f1_score для нормализованной валидационной выборки составляет: 0.83\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.833\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(criterion = 'entropy',\n",
    "                                      max_depth = 31, \n",
    "                                      min_samples_leaf = 5, \n",
    "                                      n_estimators = 170,\n",
    "                                      random_state = random_state)\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_val_rfc = rfc.predict(X_valid_scaled)\n",
    "y_pred_test_rfc = rfc.predict(X_test_scaled)\n",
    "\n",
    "f1_score_val = round(metrics.f1_score(y_valid, y_pred_val_rfc),3)\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_rfc),3)\n",
    "\n",
    "print('Модель Random Forest с подобранными гиперпараметрами RandomizedSearchCV')\n",
    "print(f'f1_score для нормализованной валидационной выборки составляет: {f1_score_val}')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99aa9c6",
   "metadata": {},
   "source": [
    "Результат для тестовой выборки улучшен.\n",
    "\n",
    "Для базовой модели: f1_score = 0.828\n",
    "\n",
    "Для GridSearchCV модели: f1_score = 0.831\n",
    "\n",
    "Для RandomizedSearchCV модели: f1_score = 0.833"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5a516a",
   "metadata": {},
   "source": [
    "#### Выводы по RandomizedSearchCV\n",
    "\n",
    "1. RandomizedSearchCV для Логистической регрессии не принес ничего, значение целевой метрики даже немного ухудшилось. \n",
    "\n",
    "2. GridSearchCV для Случайного Леса принес результат - подобрав параметры мы смогли еще немного увеличить значение целевой метрики. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd23f1",
   "metadata": {},
   "source": [
    "#### Общий вывод по простым алгоритмам подбора параметров\n",
    "Сами алгоритмы работают, подбирают необходимые параметры и иногда, можно добиться ощутимого увеличения целевой метрики.\n",
    "\n",
    "При этом нужно запастись терпением и временем для перебора различных вариантов гиперпараметров.\n",
    "\n",
    "В целом, RandomizedSearchCV лучше справляется, чем GridSearchCV - быстрее и качественнее. Можно скормить ему больше вариантов параметров, это не увеличивает время на подбор, но больше вероятность попасть в нужный набор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a733d",
   "metadata": {},
   "source": [
    "### <center> Продвинутая оптимизация включает в себя алгоритмы: Tree-Structured Parzen Estimators (TPE) библиотеки Hyperopt  и библиотеку OPTUNA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa8ad17",
   "metadata": {},
   "source": [
    " ### <center> 1. Hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5bf14",
   "metadata": {},
   "source": [
    "Сначала подберем параметры для модели Логистической Регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a22b506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "space_lr = {'penalty': hp.choice('penalty', ['l2', 'none']), \n",
    "            'solver': hp.choice('solver', ['newton-cg', 'lbfgs', 'sag', 'saga']),\n",
    "            #'C': hp.loguniform('C', low=-0.1*np.log(10), high=0.1*np.log(10)), # не улучшает результат, замедляет работу \n",
    "            'max_iter': hp.quniform('max_iter', 100, 1000, 1)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e815b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Необходимо создать функцию для минимизации \n",
    "# Она должна принимать словарь значений гиперпараметров и возвращать значение целевой функции\n",
    "# Подбирать параметры будем на валидационной выборке\n",
    "\n",
    "def hyperopt_lr(params, cv = 5, X = X_valid_scaled, y = y_valid, random_state = random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'penalty': str(params['penalty']),\n",
    "              'solver': str(params['solver']),\n",
    "              #'C': float(params['C']),\n",
    "              'max_iter': int(params['max_iter'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = linear_model.LogisticRegression(**params, random_state = random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    print(params, score)\n",
    "    return -score\n",
    "\n",
    "# И та же функция, только обучение модели проводится с помощью кросс-валидации\n",
    "# При этом, кросс-валидацию проведем на тренировочной выборке\n",
    "\n",
    "def hyperopt_lr_cv(params, cv = 5, X = X_train_scaled, y = y_train, random_state = random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'penalty': params['penalty'],\n",
    "              'solver': params['solver'],\n",
    "              #'C': float(params['C']),\n",
    "              'max_iter': int(params['max_iter'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = linear_model.LogisticRegression(**params, random_state = random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    score = cross_val_score(model, X, y, cv = cv, scoring = \"f1\", n_jobs = -1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    print(params, score)\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86b0d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'none', 'solver': 'newton-cg', 'max_iter': 658}                                                            \n",
      "1.0                                                                                                                    \n",
      "{'penalty': 'l2', 'solver': 'saga', 'max_iter': 647}                                                                   \n",
      "0.9900497512437811                                                                                                     \n",
      "{'penalty': 'l2', 'solver': 'newton-cg', 'max_iter': 166}                                                              \n",
      "0.9900497512437811                                                                                                     \n",
      "{'penalty': 'l2', 'solver': 'sag', 'max_iter': 291}                                                                    \n",
      "0.9900497512437811                                                                                                     \n",
      "{'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 187}                                                                \n",
      "1.0                                                                                                                    \n",
      "{'penalty': 'none', 'solver': 'sag', 'max_iter': 245}                                                                  \n",
      "0.9925187032418954                                                                                                     \n",
      "{'penalty': 'none', 'solver': 'sag', 'max_iter': 997}                                                                  \n",
      "1.0                                                                                                                    \n",
      "{'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 847}                                                                  \n",
      "0.9900497512437811                                                                                                     \n",
      "{'penalty': 'none', 'solver': 'newton-cg', 'max_iter': 794}                                                            \n",
      "1.0                                                                                                                    \n",
      "{'penalty': 'l2', 'solver': 'saga', 'max_iter': 533}                                                                   \n",
      "0.9900497512437811                                                                                                     \n",
      "{'penalty': 'l2', 'solver': 'newton-cg', 'max_iter': 137}                                                              \n",
      "0.9900497512437811                                                                                                     \n",
      "{'penalty': 'none', 'solver': 'saga', 'max_iter': 647}                                                                 \n",
      "0.9925187032418954                                                                                                     \n",
      "{'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 757}                                                                  \n",
      "0.9900497512437811                                                                                                     \n",
      "{'penalty': 'l2', 'solver': 'sag', 'max_iter': 520}                                                                    \n",
      "0.9900497512437811                                                                                                     \n",
      "{'penalty': 'l2', 'solver': 'sag', 'max_iter': 915}                                                                    \n",
      "0.9900497512437811                                                                                                     \n",
      "{'penalty': 'none', 'solver': 'newton-cg', 'max_iter': 989}                                                            \n",
      "1.0                                                                                                                    \n",
      "{'penalty': 'none', 'solver': 'sag', 'max_iter': 833}                                                                  \n",
      "0.9975062344139651                                                                                                     \n",
      "{'penalty': 'l2', 'solver': 'sag', 'max_iter': 193}                                                                    \n",
      "0.9875311720698254                                                                                                     \n",
      "{'penalty': 'l2', 'solver': 'saga', 'max_iter': 865}                                                                   \n",
      "0.9900497512437811                                                                                                     \n",
      "{'penalty': 'l2', 'solver': 'newton-cg', 'max_iter': 742}                                                              \n",
      "0.9900497512437811                                                                                                     \n",
      "100%|██████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/trial, best loss: -1.0]\n",
      "{'max_iter': 658.0, 'penalty': 1, 'solver': 0}\n",
      "Наилучшие значения гиперпараметров {'max_iter': 658.0, 'penalty': 1, 'solver': 0}\n"
     ]
    }
   ],
   "source": [
    "# начинаем подбор гиперпараметров\n",
    "trials_lr = Trials() # используется для логирования результатов\n",
    "\n",
    "best = fmin(hyperopt_lr, # наша функция \n",
    "            space = space_lr, # пространство гиперпараметров\n",
    "            algo = tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "            max_evals = 20, # максимальное количество итераций\n",
    "            trials = trials_lr, # логирование результатов\n",
    "            rstate = np.random.default_rng(random_state) # фиксируем для повторяемости результата\n",
    "            #rstate = np.random.RandomState(random_state) # для версии Hyperopt ниже 0.2.7\n",
    "           )\n",
    "print(best)\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b548f1e",
   "metadata": {},
   "source": [
    "С помощью библиотеки Hyperopt были подобраны следующие параметры для Логистической регрессии:\n",
    "\n",
    "- max_iter = 658\n",
    "- penalty = 'none'\n",
    "- solver = 'newton-cg'\n",
    "\n",
    "Построим модель с этими параметрами и посчитаем f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "128fd010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Logistic Regression с подобранными гиперпараметрами модулем Hyperopt\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.706\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(max_iter = 658, \n",
    "                                     penalty = 'none', \n",
    "                                     solver='newton-cg',\n",
    "                                     random_state = random_state)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_test_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_lr),3)\n",
    "\n",
    "print('Модель Logistic Regression с подобранными гиперпараметрами модулем Hyperopt')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120a38ee",
   "metadata": {},
   "source": [
    "На валидационной выборке значение f1_score = 1\n",
    "\n",
    "Но на тестовой выборке, значение упало.\n",
    "\n",
    "Возможно, наблюдается переобучение..\n",
    "Попробуем подставить параметры, при которых значение f1_score на валидационной выборке не близко к 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0815889b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Logistic Regression с подобранными гиперпараметрами модулем Hyperopt\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.807\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(max_iter = 533, \n",
    "                                     penalty = 'l2',\n",
    "                                     solver='saga',\n",
    "                                     random_state = random_state)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_test_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_lr),3)\n",
    "\n",
    "print('Модель Logistic Regression с подобранными гиперпараметрами модулем Hyperopt')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c7f9d",
   "metadata": {},
   "source": [
    "Метрика улучшилась.. \n",
    "\n",
    "Попробуем посчитать метрику на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c4a1a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 20/20 [00:00<?, ?trial/s, best loss=?]\n",
      "{'max_iter': 658.0, 'penalty': 1, 'solver': 0}\n",
      "Наилучшие значения гиперпараметров {'max_iter': 658.0, 'penalty': 1, 'solver': 0}\n"
     ]
    }
   ],
   "source": [
    "# начинаем подбор гиперпараметров с кросс-валидацией \n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best = fmin(hyperopt_lr_cv, # наша функция \n",
    "            space = space_lr, # пространство гиперпараметров\n",
    "            algo = tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "            max_evals = 20, # максимальное количество итераций\n",
    "            trials = trials_lr, # логирование результатов\n",
    "            rstate = np.random.default_rng(random_state) # фиксируем для повторяемости результата\n",
    "            #rstate = np.random.RandomState(random_state) # для версии Hyperopt ниже 0.2.7\n",
    "           )\n",
    "print(best)\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d6226",
   "metadata": {},
   "source": [
    "На кросс-валидации показывает лучшие параметры:\n",
    "\n",
    "- max_iter = 647\n",
    "- penalty = 'l2'\n",
    "- solver = 'saga'\n",
    "\n",
    "тогда f1_score = 0.806.\n",
    "\n",
    "Но, в одном из многочисленных опытов, выяснилось, что max_iter = 533 дает результат 0.807\n",
    "\n",
    "Это не катастрофически лучше, но тем не менее..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66259f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Logistic Regression (СV) с подобранными гиперпараметрами модулем Hyperopt\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.807\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(max_iter = 533, \n",
    "                                     penalty = 'l2',\n",
    "                                     solver='saga',\n",
    "                                     random_state = random_state)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_test_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_lr),3)\n",
    "\n",
    "print('Модель Logistic Regression (СV) с подобранными гиперпараметрами модулем Hyperopt')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0cd87f",
   "metadata": {},
   "source": [
    "Промежуточный итог для Логистической регрессии\n",
    "\n",
    "- Для базовой модели: f1_score = 0.802\n",
    "\n",
    "- Для GridSearchCV модели: f1_score = 0.806\n",
    "\n",
    "- Для RandomizedSearchCV модели: f1_score = 0.799\n",
    "\n",
    "- Для Hyperopt модели: f1_score = 0.807\n",
    "\n",
    "- Для Hyperopt модели на кросс-валидации: f1_score = 0.807"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd878e",
   "metadata": {},
   "source": [
    "Подберем параметры для Случайного Леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e3751e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_rf = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
    "            'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n",
    "            'max_depth': hp.quniform('max_depth', 15, 26, 1),\n",
    "            'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb091459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Необходимо создать такие же функции для минимизации, как и для логистической Регрессии \n",
    "\n",
    "def hyperopt_rf(params, X = X_valid_scaled, y = y_valid, random_state = random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'criterion': params['criterion'],\n",
    "              'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']),\n",
    "              'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "             }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    print(params, score)\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score\n",
    "\n",
    "# И та же функция, только обучение модели проводится с помощью кросс-валидации\n",
    "def hyperopt_rf_cv(params, cv = 5, X = X_train_scaled, y = y_train, random_state = random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'criterion': params['criterion'],\n",
    "              'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']),\n",
    "              'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    score = cross_val_score(model, X, y, cv = cv, scoring = \"f1\", n_jobs = -1).mean()\n",
    "\n",
    "    print(params, score)\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a09d1f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'n_estimators': 181, 'max_depth': 25, 'min_samples_leaf': 7}                                  \n",
      "0.9408866995073892                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 130, 'max_depth': 24, 'min_samples_leaf': 7}                                     \n",
      "0.9261083743842363                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 115, 'max_depth': 22, 'min_samples_leaf': 3}                                     \n",
      "0.99                                                                                                                   \n",
      "{'criterion': 'entropy', 'n_estimators': 140, 'max_depth': 22, 'min_samples_leaf': 4}                                  \n",
      "0.9850746268656716                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 150, 'max_depth': 18, 'min_samples_leaf': 3}                                  \n",
      "0.9975062344139651                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 3}                                     \n",
      "0.9925187032418954                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 170, 'max_depth': 16, 'min_samples_leaf': 10}                                 \n",
      "0.9108910891089109                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 106, 'max_depth': 23, 'min_samples_leaf': 9}                                  \n",
      "0.9158415841584159                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 172, 'max_depth': 16, 'min_samples_leaf': 8}                                  \n",
      "0.9336609336609337                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 133, 'max_depth': 20, 'min_samples_leaf': 6}                                  \n",
      "0.9580246913580247                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 103, 'max_depth': 18, 'min_samples_leaf': 2}                                  \n",
      "1.0                                                                                                                    \n",
      "{'criterion': 'gini', 'n_estimators': 178, 'max_depth': 16, 'min_samples_leaf': 7}                                     \n",
      "0.9336609336609337                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 128, 'max_depth': 22, 'min_samples_leaf': 8}                                  \n",
      "0.9336609336609337                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 107, 'max_depth': 16, 'min_samples_leaf': 6}                                     \n",
      "0.9481481481481482                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 123, 'max_depth': 15, 'min_samples_leaf': 9}                                     \n",
      "0.903225806451613                                                                                                      \n",
      "{'criterion': 'entropy', 'n_estimators': 188, 'max_depth': 17, 'min_samples_leaf': 10}                                 \n",
      "0.9090909090909091                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 188, 'max_depth': 24, 'min_samples_leaf': 9}                                     \n",
      "0.9086419753086419                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 132, 'max_depth': 19, 'min_samples_leaf': 3}                                  \n",
      "0.9975062344139651                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 125, 'max_depth': 16, 'min_samples_leaf': 9}                                     \n",
      "0.9004975124378111                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 145, 'max_depth': 26, 'min_samples_leaf': 8}                                  \n",
      "0.935960591133005                                                                                                      \n",
      "100%|██████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.47trial/s, best loss: -1.0]\n",
      "Наилучшие значения гиперпараметров {'criterion': 0, 'max_depth': 18.0, 'min_samples_leaf': 2.0, 'n_estimators': 103.0}\n"
     ]
    }
   ],
   "source": [
    "trials_rf = Trials() # используется для логирования результатов\n",
    "\n",
    "best = fmin(hyperopt_rf, # наша функция \n",
    "            space = space_rf, # пространство гиперпараметров\n",
    "            algo = tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "            max_evals = 20, # максимальное количество итераций\n",
    "            trials = trials_rf, # логирование результатов\n",
    "            rstate = np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "            #rstate = np.random.RandomState(random_state) # для версии Hyperopt ниже 0.2.7\n",
    "           )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f396891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Random Forest с подобранными гиперпараметрами Hyperopt\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.831\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(criterion = 'entropy',\n",
    "                                      max_depth = 18, \n",
    "                                      min_samples_leaf = 2, \n",
    "                                      n_estimators = 103,\n",
    "                                      random_state = random_state)\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_test_rfc = rfc.predict(X_test_scaled)\n",
    "\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_rfc),3)\n",
    "\n",
    "print('Модель Random Forest с подобранными гиперпараметрами Hyperopt')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e9b912",
   "metadata": {},
   "source": [
    "Значение метрики ухудшилось по сравнению с методом RandomizedSearchCV\n",
    "\n",
    "Попробуем на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f33e15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'n_estimators': 181, 'max_depth': 25, 'min_samples_leaf': 7}                                  \n",
      "0.8011882589423148                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 130, 'max_depth': 24, 'min_samples_leaf': 7}                                     \n",
      "0.7987389095117854                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 115, 'max_depth': 22, 'min_samples_leaf': 3}                                     \n",
      "0.8046667895171721                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 140, 'max_depth': 22, 'min_samples_leaf': 4}                                  \n",
      "0.8080729413935597                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 150, 'max_depth': 18, 'min_samples_leaf': 3}                                  \n",
      "0.8063938433590842                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 175, 'max_depth': 20, 'min_samples_leaf': 3}                                     \n",
      "0.806979350732475                                                                                                      \n",
      "{'criterion': 'entropy', 'n_estimators': 170, 'max_depth': 16, 'min_samples_leaf': 10}                                 \n",
      "0.7908988816238482                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 106, 'max_depth': 23, 'min_samples_leaf': 9}                                  \n",
      "0.7981667957123358                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 172, 'max_depth': 16, 'min_samples_leaf': 8}                                  \n",
      "0.7924695677838082                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 133, 'max_depth': 20, 'min_samples_leaf': 6}                                  \n",
      "0.8010714380057704                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 103, 'max_depth': 18, 'min_samples_leaf': 2}                                  \n",
      "0.8094415888501437                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 178, 'max_depth': 16, 'min_samples_leaf': 7}                                     \n",
      "0.7988198795418617                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 128, 'max_depth': 22, 'min_samples_leaf': 8}                                  \n",
      "0.7924080918937938                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 107, 'max_depth': 16, 'min_samples_leaf': 6}                                     \n",
      "0.7938828954627692                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 123, 'max_depth': 15, 'min_samples_leaf': 9}                                     \n",
      "0.7914303627451298                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 188, 'max_depth': 17, 'min_samples_leaf': 10}                                 \n",
      "0.7946000801132007                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 188, 'max_depth': 24, 'min_samples_leaf': 9}                                     \n",
      "0.79596339204926                                                                                                       \n",
      "{'criterion': 'entropy', 'n_estimators': 132, 'max_depth': 19, 'min_samples_leaf': 3}                                  \n",
      "0.8105646217846983                                                                                                     \n",
      "{'criterion': 'gini', 'n_estimators': 125, 'max_depth': 16, 'min_samples_leaf': 9}                                     \n",
      "0.7908865917051033                                                                                                     \n",
      "{'criterion': 'entropy', 'n_estimators': 145, 'max_depth': 26, 'min_samples_leaf': 8}                                  \n",
      "0.7950201238881542                                                                                                     \n",
      "100%|███████████████████████████████████████████████| 20/20 [00:49<00:00,  2.47s/trial, best loss: -0.8105646217846983]\n",
      "Наилучшие значения гиперпараметров {'criterion': 0, 'max_depth': 19.0, 'min_samples_leaf': 3.0, 'n_estimators': 132.0}\n"
     ]
    }
   ],
   "source": [
    "trials_rf_cv = Trials() # используется для логирования результатов\n",
    "\n",
    "best = fmin(hyperopt_rf_cv, # наша функция \n",
    "            space = space_rf, # пространство гиперпараметров\n",
    "            algo = tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "            max_evals = 20, # максимальное количество итераций\n",
    "            trials = trials_rf_cv, # логирование результатов\n",
    "            rstate = np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "            #rstate = np.random.RandomState(random_state) # для версии Hyperopt ниже 0.2.7\n",
    "           )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fb1d1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Random Forest (CV) с подобранными гиперпараметрами Hyperopt\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.834\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(criterion = 'entropy',\n",
    "                                      max_depth = 19, \n",
    "                                      min_samples_leaf = 3, \n",
    "                                      n_estimators = 132,\n",
    "                                      random_state = random_state)\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_test_rfc = rfc.predict(X_test_scaled)\n",
    "\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_rfc),3)\n",
    "\n",
    "print('Модель Random Forest (CV) с подобранными гиперпараметрами Hyperopt')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ae2f9f",
   "metadata": {},
   "source": [
    "Результат улучшен"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41de52",
   "metadata": {},
   "source": [
    "Промежуточный итог для Случайного Леса\n",
    "\n",
    "- Для базовой модели: f1_score = 0.828\n",
    "\n",
    "- Для GridSearchCV модели: f1_score = 0.831\n",
    "\n",
    "- Для RandomizedSearchCV модели: f1_score = 0.833\n",
    "\n",
    "- Для Hyperopt модели: f1_score = 0.831\n",
    "\n",
    "- Для Hyperopt модели на кросс-валидации: f1_score = 0.834"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f768c",
   "metadata": {},
   "source": [
    " ### <center> 2. OPTUNA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052eca59",
   "metadata": {},
   "source": [
    "Для Логистической Регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f73ed99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция оптимизации гиперпараметров с помощью OPTUNA\n",
    "def optuna_lr(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', 'none'])\n",
    "    solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'sag', 'saga'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000, 1)\n",
    "\n",
    "    \n",
    "    # создаем модель\n",
    "    model = linear_model.LogisticRegression(penalty = penalty,\n",
    "                                            solver = solver,\n",
    "                                            max_iter = max_iter,\n",
    "                                            random_state=random_state)\n",
    "    # обучаем модель\n",
    "    model.fit(X_valid_scaled, y_valid)\n",
    "    score = metrics.f1_score(y_valid, model.predict(X_valid_scaled))\n",
    "\n",
    "    return score\n",
    "\n",
    "# Функция оптимизации гиперпараметров на кросс-валидации с помощью OPTUNA\n",
    "def optuna_lr_cv(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', 'none'])\n",
    "    solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'sag', 'saga'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000, 1)\n",
    "\n",
    "    \n",
    "    # создаем модель\n",
    "    model = linear_model.LogisticRegression(penalty = penalty,\n",
    "                                            solver = solver,\n",
    "                                            max_iter = max_iter,\n",
    "                                            random_state=random_state)\n",
    "    # обучаем модель\n",
    "    score = cross_val_score(model, X_train_scaled, y_train, cv = 5, scoring = \"f1\", n_jobs = -1).mean()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2e41ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-15 11:14:55,730]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:14:55,857]\u001b[0m Trial 0 finished with value: 0.9900497512437811 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'max_iter': 131}. Best is trial 0 with value: 0.9900497512437811.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:14:55,882]\u001b[0m Trial 1 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 287}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:14:57,746]\u001b[0m Trial 2 finished with value: 0.9950248756218906 and parameters: {'penalty': 'none', 'solver': 'sag', 'max_iter': 422}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:14:57,767]\u001b[0m Trial 3 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 510}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:01,602]\u001b[0m Trial 4 finished with value: 0.9975062344139651 and parameters: {'penalty': 'none', 'solver': 'sag', 'max_iter': 907}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:03,033]\u001b[0m Trial 5 finished with value: 0.9900497512437811 and parameters: {'penalty': 'l2', 'solver': 'sag', 'max_iter': 314}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:04,655]\u001b[0m Trial 6 finished with value: 0.9900497512437811 and parameters: {'penalty': 'none', 'solver': 'saga', 'max_iter': 352}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:04,753]\u001b[0m Trial 7 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'max_iter': 681}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:06,185]\u001b[0m Trial 8 finished with value: 0.9900497512437811 and parameters: {'penalty': 'l2', 'solver': 'sag', 'max_iter': 359}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:06,895]\u001b[0m Trial 9 finished with value: 0.9775561097256857 and parameters: {'penalty': 'l2', 'solver': 'saga', 'max_iter': 139}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:06,934]\u001b[0m Trial 10 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 693}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:06,951]\u001b[0m Trial 11 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 560}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:06,983]\u001b[0m Trial 12 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 508}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:07,014]\u001b[0m Trial 13 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 252}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:07,030]\u001b[0m Trial 14 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 611}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:07,061]\u001b[0m Trial 15 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 896}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:07,092]\u001b[0m Trial 16 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 448}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:07,124]\u001b[0m Trial 17 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 229}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:10,471]\u001b[0m Trial 18 finished with value: 0.9900497512437811 and parameters: {'penalty': 'l2', 'solver': 'saga', 'max_iter': 759}. Best is trial 1 with value: 1.0.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:10,560]\u001b[0m Trial 19 finished with value: 1.0 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'max_iter': 447}. Best is trial 1 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 287}\n",
      "f1_score на валидационном наборе: 1.00\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name = \"LogisticRegression\", direction = \"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_lr, n_trials = 20)\n",
    "\n",
    "# выводим результаты на валидационной выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на валидационном наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cc282e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Logistic Regression с подобранными гиперпараметрами модулем OPTUNA\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.778\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(max_iter = 131,\n",
    "                                     penalty = 'none',\n",
    "                                     solver = 'lbfgs',\n",
    "                                     random_state = random_state)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_test_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_lr),3)\n",
    "\n",
    "print('Модель Logistic Regression с подобранными гиперпараметрами модулем OPTUNA')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d4384",
   "metadata": {},
   "source": [
    "Значение метрики упало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d3a3245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-15 11:15:11,067]\u001b[0m A new study created in memory with name: LogisticRegressionCV\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:15:47,697]\u001b[0m Trial 0 finished with value: 0.7536485309834857 and parameters: {'penalty': 'none', 'solver': 'sag', 'max_iter': 898}. Best is trial 0 with value: 0.7536485309834857.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:16:37,974]\u001b[0m Trial 1 finished with value: 0.718947085971792 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'max_iter': 527}. Best is trial 0 with value: 0.7536485309834857.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:16:43,993]\u001b[0m Trial 2 finished with value: 0.7731519590660247 and parameters: {'penalty': 'none', 'solver': 'saga', 'max_iter': 129}. Best is trial 2 with value: 0.7731519590660247.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:17:14,673]\u001b[0m Trial 3 finished with value: 0.7621198163423093 and parameters: {'penalty': 'none', 'solver': 'saga', 'max_iter': 695}. Best is trial 2 with value: 0.7731519590660247.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:17:44,771]\u001b[0m Trial 4 finished with value: 0.7736756508916951 and parameters: {'penalty': 'l2', 'solver': 'saga', 'max_iter': 734}. Best is trial 4 with value: 0.7736756508916951.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:17:50,023]\u001b[0m Trial 5 finished with value: 0.7355750080148303 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 374}. Best is trial 4 with value: 0.7736756508916951.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:18:40,205]\u001b[0m Trial 6 finished with value: 0.718947085971792 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'max_iter': 366}. Best is trial 4 with value: 0.7736756508916951.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:18:49,164]\u001b[0m Trial 7 finished with value: 0.7312924952113757 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'max_iter': 823}. Best is trial 4 with value: 0.7736756508916951.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:19:30,851]\u001b[0m Trial 8 finished with value: 0.759875889924058 and parameters: {'penalty': 'none', 'solver': 'saga', 'max_iter': 975}. Best is trial 4 with value: 0.7736756508916951.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:19:48,352]\u001b[0m Trial 9 finished with value: 0.7624104417074878 and parameters: {'penalty': 'none', 'solver': 'saga', 'max_iter': 398}. Best is trial 4 with value: 0.7736756508916951.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:20:05,203]\u001b[0m Trial 10 finished with value: 0.7732911156874552 and parameters: {'penalty': 'l2', 'solver': 'sag', 'max_iter': 696}. Best is trial 4 with value: 0.7736756508916951.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:20:21,478]\u001b[0m Trial 11 finished with value: 0.7732911156874552 and parameters: {'penalty': 'l2', 'solver': 'sag', 'max_iter': 686}. Best is trial 4 with value: 0.7736756508916951.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:20:37,813]\u001b[0m Trial 12 finished with value: 0.7732911156874552 and parameters: {'penalty': 'l2', 'solver': 'sag', 'max_iter': 729}. Best is trial 4 with value: 0.7736756508916951.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:20:54,715]\u001b[0m Trial 13 finished with value: 0.7732911156874552 and parameters: {'penalty': 'l2', 'solver': 'sag', 'max_iter': 571}. Best is trial 4 with value: 0.7736756508916951.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:21:19,209]\u001b[0m Trial 14 finished with value: 0.7736777080219648 and parameters: {'penalty': 'l2', 'solver': 'saga', 'max_iter': 543}. Best is trial 14 with value: 0.7736777080219648.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:21:44,614]\u001b[0m Trial 15 finished with value: 0.7736777080219648 and parameters: {'penalty': 'l2', 'solver': 'saga', 'max_iter': 541}. Best is trial 14 with value: 0.7736777080219648.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:08,135]\u001b[0m Trial 16 finished with value: 0.7734442649703972 and parameters: {'penalty': 'l2', 'solver': 'saga', 'max_iter': 518}. Best is trial 14 with value: 0.7736777080219648.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:15,187]\u001b[0m Trial 17 finished with value: 0.7719824603571694 and parameters: {'penalty': 'l2', 'solver': 'saga', 'max_iter': 146}. Best is trial 14 with value: 0.7736777080219648.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:25,280]\u001b[0m Trial 18 finished with value: 0.7728687375089471 and parameters: {'penalty': 'l2', 'solver': 'saga', 'max_iter': 223}. Best is trial 14 with value: 0.7736777080219648.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:30,193]\u001b[0m Trial 19 finished with value: 0.7742813453550152 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 442}. Best is trial 19 with value: 0.7742813453550152.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 442}\n",
      "f1_score на валидационном наборе: 0.77\n",
      "Wall time: 7min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name = \"LogisticRegressionCV\", direction = \"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_lr_cv, n_trials = 20)\n",
    "\n",
    "# выводим результаты на валидационной выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на валидационном наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "444cd217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Logistic Regression CV с подобранными гиперпараметрами модулем OPTUNA\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.806\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(max_iter = 573, \n",
    "                                     penalty = 'l2',\n",
    "                                     solver='lbfgs',\n",
    "                                     random_state = random_state)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_test_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_lr),3)\n",
    "\n",
    "print('Модель Logistic Regression CV с подобранными гиперпараметрами модулем OPTUNA')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd9e1c",
   "metadata": {},
   "source": [
    "Итоги для Логистической Регрессии\n",
    "\n",
    "- Для базовой модели: f1_score = 0.802\n",
    "\n",
    "- Для GridSearchCV модели: f1_score = 0.806\n",
    "\n",
    "- Для RandomizedSearchCV модели: f1_score = 0.799\n",
    "\n",
    "- Для Hyperopt модели: f1_score = 0.807\n",
    "\n",
    "- Для Hyperopt модели на кросс-валидации: f1_score = 0.807\n",
    "    \n",
    "- Для OPTUNA модели: f1_score = 0.778\n",
    "    \n",
    "- Для OPTUNA модели на кросс-валидации: f1_score = 0.806\n",
    "\n",
    "\n",
    "###### Наилучшим образом справился алгоритм Hyperopt. При этом, и на валидационной выборке, и на кросс-валидации параметры были подабраны таким образом, что дали наибольший показатель f1_score = 0.807"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f57a05",
   "metadata": {},
   "source": [
    "Для Случайного Леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f56db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция оптимизации гиперпараметров с помощью OPTUNA\n",
    "def optuna_rf(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    criterion = trial.suggest_categorical('criterion', ['entropy', 'gini'])\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
    "\n",
    "    # создаем модель\n",
    "    model = ensemble.RandomForestClassifier(n_estimators = n_estimators,\n",
    "                                            max_depth = max_depth,\n",
    "                                            min_samples_leaf = min_samples_leaf,\n",
    "                                            random_state = random_state)\n",
    "    # обучаем модель\n",
    "    model.fit(X_valid_scaled, y_valid)\n",
    "    score = metrics.f1_score(y_valid, model.predict(X_valid_scaled))\n",
    "\n",
    "    return score\n",
    "\n",
    "# Функция оптимизации гиперпараметров на кросс-валидации с помощью OPTUNA\n",
    "def optuna_rf_cv(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    criterion = trial.suggest_categorical('criterion', ['entropy', 'gini'])\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
    "\n",
    "    # создаем модель\n",
    "    model = ensemble.RandomForestClassifier(n_estimators = n_estimators,\n",
    "                                            max_depth = max_depth,\n",
    "                                            min_samples_leaf = min_samples_leaf,\n",
    "                                            random_state = random_state)\n",
    "    # обучаем модель\n",
    "    score = cross_val_score(model, X_train_scaled, y_train, cv = 5, scoring = \"f1\", n_jobs = -1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c22a75",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры для модели RandomForest на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6d8b1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-15 11:22:31,696]\u001b[0m A new study created in memory with name: RandomForest\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:31,956]\u001b[0m Trial 0 finished with value: 0.9605911330049262 and parameters: {'criterion': 'entropy', 'n_estimators': 178, 'max_depth': 16, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9605911330049262.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:32,076]\u001b[0m Trial 1 finished with value: 0.9874686716791979 and parameters: {'criterion': 'gini', 'n_estimators': 103, 'max_depth': 17, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.9874686716791979.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:32,287]\u001b[0m Trial 2 finished with value: 0.9925187032418954 and parameters: {'criterion': 'entropy', 'n_estimators': 143, 'max_depth': 24, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.9925187032418954.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:32,500]\u001b[0m Trial 3 finished with value: 0.9211822660098522 and parameters: {'criterion': 'gini', 'n_estimators': 188, 'max_depth': 13, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.9925187032418954.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:32,762]\u001b[0m Trial 4 finished with value: 0.9950248756218906 and parameters: {'criterion': 'gini', 'n_estimators': 198, 'max_depth': 13, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9950248756218906.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:32,958]\u001b[0m Trial 5 finished with value: 0.9313725490196079 and parameters: {'criterion': 'entropy', 'n_estimators': 167, 'max_depth': 21, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.9950248756218906.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:33,142]\u001b[0m Trial 6 finished with value: 0.9950248756218906 and parameters: {'criterion': 'gini', 'n_estimators': 138, 'max_depth': 18, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9950248756218906.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:33,354]\u001b[0m Trial 7 finished with value: 0.9950248756218906 and parameters: {'criterion': 'gini', 'n_estimators': 150, 'max_depth': 14, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9950248756218906.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:33,554]\u001b[0m Trial 8 finished with value: 0.9925187032418954 and parameters: {'criterion': 'entropy', 'n_estimators': 164, 'max_depth': 12, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.9950248756218906.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:33,688]\u001b[0m Trial 9 finished with value: 0.9261083743842363 and parameters: {'criterion': 'entropy', 'n_estimators': 103, 'max_depth': 13, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.9950248756218906.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:33,925]\u001b[0m Trial 10 finished with value: 0.9605911330049262 and parameters: {'criterion': 'gini', 'n_estimators': 200, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.9950248756218906.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:34,091]\u001b[0m Trial 11 finished with value: 0.9 and parameters: {'criterion': 'gini', 'n_estimators': 130, 'max_depth': 10, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.9950248756218906.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:34,267]\u001b[0m Trial 12 finished with value: 0.9975186104218362 and parameters: {'criterion': 'gini', 'n_estimators': 129, 'max_depth': 20, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.9975186104218362.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:34,428]\u001b[0m Trial 13 finished with value: 0.967741935483871 and parameters: {'criterion': 'gini', 'n_estimators': 122, 'max_depth': 24, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.9975186104218362.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:34,593]\u001b[0m Trial 14 finished with value: 0.9975186104218362 and parameters: {'criterion': 'gini', 'n_estimators': 118, 'max_depth': 21, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.9975186104218362.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:34,740]\u001b[0m Trial 15 finished with value: 0.967741935483871 and parameters: {'criterion': 'gini', 'n_estimators': 117, 'max_depth': 22, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.9975186104218362.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:34,897]\u001b[0m Trial 16 finished with value: 0.8982630272952854 and parameters: {'criterion': 'gini', 'n_estimators': 116, 'max_depth': 28, 'min_samples_leaf': 10}. Best is trial 12 with value: 0.9975186104218362.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:35,068]\u001b[0m Trial 17 finished with value: 0.9533169533169533 and parameters: {'criterion': 'gini', 'n_estimators': 129, 'max_depth': 25, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.9975186104218362.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:35,253]\u001b[0m Trial 18 finished with value: 0.9751243781094527 and parameters: {'criterion': 'gini', 'n_estimators': 152, 'max_depth': 19, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.9975186104218362.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:35,428]\u001b[0m Trial 19 finished with value: 0.9975186104218362 and parameters: {'criterion': 'gini', 'n_estimators': 112, 'max_depth': 21, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.9975186104218362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'criterion': 'gini', 'n_estimators': 129, 'max_depth': 20, 'min_samples_leaf': 2}\n",
      "f1_score на валидационном наборе: 1.00\n",
      "Wall time: 3.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name = \"RandomForest\", direction = \"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf, n_trials = 20)\n",
    "\n",
    "# выводим результаты на валидационной выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на валидационном наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "916a7b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Random Forest с подобранными гиперпараметрами OPTUNA\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.846\n"
     ]
    }
   ],
   "source": [
    "# Считаем метрику на тесте\n",
    "rfc = ensemble.RandomForestClassifier(criterion = 'entropy',\n",
    "                                      max_depth = 30, \n",
    "                                      min_samples_leaf = 2, \n",
    "                                      n_estimators = 164,\n",
    "                                      random_state = random_state)\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_test_rfc = rfc.predict(X_test_scaled)\n",
    "\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_rfc),3)\n",
    "\n",
    "print('Модель Random Forest с подобранными гиперпараметрами OPTUNA')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779903f1",
   "metadata": {},
   "source": [
    "Значение метрики увеличилось"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657710d",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры для модели RandomForest на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77d23d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-15 11:22:37,324]\u001b[0m A new study created in memory with name: RandomForest\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:39,525]\u001b[0m Trial 0 finished with value: 0.7958983483512222 and parameters: {'criterion': 'gini', 'n_estimators': 144, 'max_depth': 16, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7958983483512222.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:41,884]\u001b[0m Trial 1 finished with value: 0.8008277221983086 and parameters: {'criterion': 'gini', 'n_estimators': 153, 'max_depth': 25, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.8008277221983086.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:44,618]\u001b[0m Trial 2 finished with value: 0.8050659189261273 and parameters: {'criterion': 'gini', 'n_estimators': 168, 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8050659189261273.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:47,154]\u001b[0m Trial 3 finished with value: 0.7924009944699584 and parameters: {'criterion': 'gini', 'n_estimators': 183, 'max_depth': 19, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.8050659189261273.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:49,209]\u001b[0m Trial 4 finished with value: 0.8021595065990603 and parameters: {'criterion': 'entropy', 'n_estimators': 128, 'max_depth': 14, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8050659189261273.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:51,179]\u001b[0m Trial 5 finished with value: 0.7992166617329325 and parameters: {'criterion': 'entropy', 'n_estimators': 132, 'max_depth': 13, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.8050659189261273.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:53,680]\u001b[0m Trial 6 finished with value: 0.8028658238256787 and parameters: {'criterion': 'entropy', 'n_estimators': 152, 'max_depth': 14, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8050659189261273.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:56,278]\u001b[0m Trial 7 finished with value: 0.7983891326909737 and parameters: {'criterion': 'gini', 'n_estimators': 184, 'max_depth': 11, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8050659189261273.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:22:58,133]\u001b[0m Trial 8 finished with value: 0.8017009682276031 and parameters: {'criterion': 'gini', 'n_estimators': 111, 'max_depth': 18, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8050659189261273.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:23:00,119]\u001b[0m Trial 9 finished with value: 0.797332978707423 and parameters: {'criterion': 'gini', 'n_estimators': 125, 'max_depth': 14, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.8050659189261273.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:23:03,419]\u001b[0m Trial 10 finished with value: 0.8065944442463211 and parameters: {'criterion': 'entropy', 'n_estimators': 200, 'max_depth': 24, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.8065944442463211.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:23:06,657]\u001b[0m Trial 11 finished with value: 0.8073500146679823 and parameters: {'criterion': 'entropy', 'n_estimators': 199, 'max_depth': 24, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.8073500146679823.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:23:09,760]\u001b[0m Trial 12 finished with value: 0.8079096884410436 and parameters: {'criterion': 'entropy', 'n_estimators': 198, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.8079096884410436.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:23:12,961]\u001b[0m Trial 13 finished with value: 0.8064983559298013 and parameters: {'criterion': 'entropy', 'n_estimators': 197, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.8079096884410436.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:23:15,638]\u001b[0m Trial 14 finished with value: 0.7994388320562105 and parameters: {'criterion': 'entropy', 'n_estimators': 175, 'max_depth': 23, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8079096884410436.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:23:18,580]\u001b[0m Trial 15 finished with value: 0.8053227131069791 and parameters: {'criterion': 'entropy', 'n_estimators': 189, 'max_depth': 28, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8079096884410436.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:23:21,286]\u001b[0m Trial 16 finished with value: 0.8012093908285944 and parameters: {'criterion': 'entropy', 'n_estimators': 173, 'max_depth': 22, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.8079096884410436.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:23:23,978]\u001b[0m Trial 17 finished with value: 0.80355144933317 and parameters: {'criterion': 'entropy', 'n_estimators': 164, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8079096884410436.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:23:26,587]\u001b[0m Trial 18 finished with value: 0.7908228776475736 and parameters: {'criterion': 'entropy', 'n_estimators': 191, 'max_depth': 22, 'min_samples_leaf': 10}. Best is trial 12 with value: 0.8079096884410436.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 11:23:29,373]\u001b[0m Trial 19 finished with value: 0.8025567928557275 and parameters: {'criterion': 'entropy', 'n_estimators': 181, 'max_depth': 27, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.8079096884410436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'criterion': 'entropy', 'n_estimators': 198, 'max_depth': 25, 'min_samples_leaf': 2}\n",
      "f1_score на валидационном наборе: 0.81\n",
      "Wall time: 52.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name = \"RandomForest\", direction = \"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf_cv, n_trials = 20)\n",
    "\n",
    "# выводим результаты на валидационной выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на валидационном наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "762de1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель Random Forest (CV) с подобранными гиперпараметрами OPTUNA\n",
      "f1_score для нормализованной тестовой выборки составляет: 0.837\n"
     ]
    }
   ],
   "source": [
    "# Считаем метрику на тесте\n",
    "rfc = ensemble.RandomForestClassifier(criterion = 'gini',\n",
    "                                      max_depth = 25, \n",
    "                                      min_samples_leaf = 2, \n",
    "                                      n_estimators = 161,\n",
    "                                      random_state = random_state)\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_test_rfc = rfc.predict(X_test_scaled)\n",
    "\n",
    "f1_score_test = round(metrics.f1_score(y_test, y_pred_test_rfc),3)\n",
    "\n",
    "print('Модель Random Forest (CV) с подобранными гиперпараметрами OPTUNA')\n",
    "print(f'f1_score для нормализованной тестовой выборки составляет: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f647662c",
   "metadata": {},
   "source": [
    "Промежуточный итог для Случайного Леса\n",
    "\n",
    "- Для базовой модели: f1_score = 0.828\n",
    "\n",
    "- Для GridSearchCV модели: f1_score = 0.831\n",
    "\n",
    "- Для RandomizedSearchCV модели: f1_score = 0.833\n",
    "\n",
    "- Для Hyperopt модели: f1_score = 0.833\n",
    "\n",
    "- Для Hyperopt модели на кросс-валидации: f1_score = 0.834\n",
    "\n",
    "- Для OPTUNA модели: f1_score = 0.846\n",
    "\n",
    "- Для OPTUNA модели на кросс-валидации: f1_score = 0.837\n",
    "\n",
    "###### Наилучшим образом с подбором гиперпараметров для Random Forest справился алгоритм OPTUNA. При этом, на валидационной выборке были найдены лучшие параметры, которые привели к максимальному значению f1_score, а на кросс-валидации параметры были подабраны таким образом, что дали лучше результат, чем все предыдущие, но не такой хороший как на валидационной выборке.\n",
    "###### f1_score = 0.846"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7eaa56",
   "metadata": {},
   "source": [
    "### <center> Итоги проделанной работы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44565074",
   "metadata": {},
   "source": [
    "#### Вводные:\n",
    "\n",
    "- Датасет был задан, данные очищены и размечены\n",
    "- Классы сбалансированы\n",
    "- Была проведена нормализация с помощью MinMaxScaler\n",
    "- Датасет разделен на тренировочную, валидационную и тестовые выборки\n",
    "- Даны 2 модели для исследования гиперпараметров: LogisticRegression и RandomForest\n",
    "- Метрика для исследования: f1_score\n",
    "\n",
    "#### Процесс работы:\n",
    "\n",
    "- Построение базовых моделей, без подбора гиперпараметров\n",
    "- Расчет метрики f1_score для каждой из моделей\n",
    "- Подбор гиперпараметров на валидационной выборке для каждой модели с помощью алгоритмов: GridSearchCV, RandomizedSearchCV, Hyperopt, OPTUNA\n",
    "- Подбор гиперпараметров на тренировочной выборке с кросс-валидацией для каждой модели с помощью вышеуказанных алгоритмов\n",
    "- Сравнение значений метрики на тестовом наборе данных f1_score на каждом из этапов для каждой модели\n",
    "\n",
    "#### Выводы:\n",
    "\n",
    "- Наилучшее значение, которое удалось добиться на данном этапе: f1_score = 0.846 удалось достичь спомощью алгоритма OPTUNA на валидационных данных.\n",
    "- Все манипуляции над моделью LogisticRegression не принесли существенного значения роста метрики f1_score (c 0.802 до 0.807)\n",
    "- LogisticRegression не подходит для данного датасета.\n",
    "- Значение f1_score для модели RandomForest удалось увеличить с 0.828 до 0.837, практически на 0.1\n",
    "- RandomForest лучше показала себя для данного датасета.\n",
    "\n",
    "#### Что дальше?:\n",
    "\n",
    "- Первое, что приходит на ум - это уменьшение количества признаков, например с помощью RFE, f_regression, f_classif, изученные нами ранее\n",
    "- Второе - протестировать другие модели машинного обучения, например алгоритмы LightGBM и XG Boost\n",
    "- Третье - применить регуляризацию Lasso или Ridge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
